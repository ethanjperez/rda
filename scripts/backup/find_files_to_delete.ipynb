{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from hurry import filesize\n",
    "import os\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = f'{os.getenv(\"HOME\")}/checkpoint/complexity'\n",
    "# exts = [os.path.splitext(file)[-1] for folder, subfolders, files in tqdm(os.walk(path)) for file in files]\n",
    "all_files = [file for folder, subfolders, files in tqdm(os.walk(path)) for file in files]\n",
    "exts = [os.path.splitext(file)[-1] for file in all_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext2count = defaultdict(int)\n",
    "for ext in exts:\n",
    "    ext2count[ext] += 1\n",
    "    \n",
    "file2count = defaultdict(int)\n",
    "for file in all_files:\n",
    "    file2count[file] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".csv 389416\n",
      ".txt 95268\n",
      ".yaml 86696\n",
      ".json 70019\n",
      ".log 39944\n",
      ".0 19567\n",
      ".loss 9218\n",
      ".bin 8815\n",
      ".1 7823\n",
      ".2 6355\n",
      ".3 6349\n",
      ".4 6121\n",
      ".5 6095\n",
      ".6 6090\n",
      ".pt 5412\n",
      ".7 4282\n",
      ".8 4276\n",
      ".9 4267\n",
      ".ckpt 124\n",
      ".10 18\n",
      ".23 18\n",
      ".11 18\n",
      ".12 18\n",
      ".31 18\n",
      ".24 18\n",
      ".37 18\n",
      ".15 18\n",
      ".22 18\n",
      ".33 18\n",
      ".14 18\n",
      ".30 18\n",
      ".35 18\n",
      ".19 18\n",
      ".21 18\n",
      ".17 18\n",
      ".18 18\n",
      ".34 18\n",
      ".36 18\n",
      ".25 18\n",
      ".29 18\n",
      ".28 18\n",
      ".13 18\n",
      ".32 18\n",
      ".16 18\n",
      ".26 18\n",
      ".20 18\n",
      ".27 18\n"
     ]
    }
   ],
   "source": [
    "for ext in sorted(ext2count, key=ext2count.get, reverse=True):\n",
    "    if ext2count[ext] <= 1:\n",
    "        break\n",
    "    print(ext, ext2count[ext])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hparams.yaml 86696\n",
      "test_results.txt 84859\n",
      "preds.val.epoch-0.csv 83477\n",
      "preds.val.epoch-1.csv 83246\n",
      "preds.test.epoch-0.csv 82744\n",
      "preds.val.epoch-2.csv 61117\n",
      "train.log 30843\n",
      "preds.val.epoch-3.csv 27598\n",
      "preds.val.epoch-4.csv 16906\n",
      "test_results.with_temperature.json 16449\n",
      "preds.val.epoch-5.csv 10887\n",
      "config.json 7724\n",
      "tokenizer_config.json 7723\n",
      "special_tokens_map.json 7723\n",
      "vocab.json 7722\n",
      "merges.txt 7720\n",
      "training_args.bin 7589\n",
      "preds.val.epoch-6.csv 7402\n",
      "scheduler.pt 5412\n",
      "preds.val.epoch-7.csv 5313\n",
      "results.json 4238\n",
      "preds.val.epoch-8.csv 3749\n",
      "preds.val.epoch-9.csv 2749\n",
      "test.log 2688\n",
      "val_results.txt 2688\n",
      "preds.test.csv 2114\n",
      "preds.val.csv 2114\n",
      "pytorch_model.bin 1226\n",
      "predictions_2784.json.loss 677\n",
      "predictions_2784.json 677\n",
      "nbest_predictions_2784.json 677\n",
      "nbest_predictions_5600.json 642\n",
      "predictions_5600.json 642\n",
      "predictions_5600.json.loss 642\n",
      "predictions_22560.json.loss 548\n",
      "predictions_22560.json 548\n",
      "nbest_predictions_22560.json 548\n",
      "predictions_1376.json.loss 548\n",
      "predictions_1376.json 548\n",
      "nbest_predictions_1376.json 548\n",
      "nbest_predictions_90400.json 531\n",
      "predictions_90400.json 531\n",
      "predictions_90400.json.loss 531\n",
      "predictions_11232.json 319\n",
      "predictions_11232.json.loss 319\n",
      "nbest_predictions_11232.json 319\n",
      "predictions_4192.json.loss 296\n",
      "predictions_4192.json 296\n",
      "nbest_predictions_4192.json 296\n",
      "predictions_45152.json 284\n",
      "nbest_predictions_45152.json 284\n",
      "predictions_45152.json.loss 284\n",
      "predictions_11264.json.loss 274\n",
      "nbest_predictions_11264.json 274\n",
      "predictions_11264.json 274\n",
      "nbest_predictions_2080.json 274\n",
      "predictions_672.json.loss 274\n",
      "predictions_2080.json 274\n",
      "predictions_672.json 274\n",
      "nbest_predictions_672.json 274\n",
      "predictions_2080.json.loss 274\n",
      "predictions_45184.json 270\n",
      "nbest_predictions_45184.json 270\n",
      "predictions_45184.json.loss 270\n",
      "nbest_predictions_180832.json 269\n",
      "predictions_180832.json.loss 269\n",
      "predictions_180832.json 269\n",
      "predictions_8416.json 268\n",
      "predictions_8416.json.loss 268\n",
      "nbest_predictions_8416.json 268\n",
      "predictions_dev2-22560.json 266\n",
      "predictions_dev2-22560.json.loss 266\n",
      "nbest_predictions_dev2-22560.json 266\n",
      "predictions_33856.json 261\n",
      "nbest_predictions_33856.json 261\n",
      "predictions_33856.json.loss 261\n",
      "predictions_16864.json 256\n",
      "nbest_predictions_16864.json 256\n",
      "predictions_16864.json.loss 256\n",
      "predictions_dev2-5600.json.loss 255\n",
      "nbest_predictions_dev2-5600.json 255\n",
      "predictions_dev2-5600.json 255\n",
      "nbest_predictions_67744.json 246\n",
      "predictions_67744.json 246\n",
      "predictions_67744.json.loss 246\n",
      "predictions_dev2-11232.json 236\n",
      "predictions_dev2-11232.json.loss 236\n",
      "nbest_predictions_dev2-11232.json 236\n",
      "predictions_dev2-45152.json 234\n",
      "predictions_dev2-45152.json.loss 234\n",
      "nbest_predictions_dev2-45152.json 234\n",
      "nbest_predictions_135616.json 230\n",
      "predictions_135616.json 230\n",
      "predictions_135616.json.loss 230\n",
      "predictions_271264.json 213\n",
      "predictions_271264.json.loss 213\n",
      "nbest_predictions_271264.json 213\n",
      "predictions_dev2-90400.json 205\n",
      "nbest_predictions_dev2-90400.json 205\n",
      "predictions_dev2-90400.json.loss 205\n",
      "nbest_predictions_dev2-180832.json 177\n",
      "predictions_dev2-180832.json.loss 177\n",
      "predictions_dev2-180832.json 177\n",
      "predictions_dev2-2080.json 167\n",
      "nbest_predictions_dev2-2080.json 167\n",
      "predictions_dev2-2080.json.loss 167\n",
      "predictions_dev2-2784.json 156\n",
      "nbest_predictions_dev2-2784.json 156\n",
      "predictions_dev2-2784.json.loss 156\n",
      "predictions_dev2-4192.json.loss 137\n",
      "nbest_predictions_dev2-4192.json 137\n",
      "predictions_dev2-4192.json 137\n",
      "bart-base.fts-0.0625.train.log 80\n",
      "bart-base.fts-0.015625.train.log 80\n",
      "checkpointepoch=0.ckpt 71\n",
      "bart-base.fts-0.0009765625.train.log 64\n",
      "bart-base.fts-0.001953125.train.log 64\n",
      "bart-base.fts-0.00390625.train.log 64\n",
      "bart-base.fts-0.00048828125.train.log 64\n",
      "bart-base.fts-0.0078125.train.log 64\n",
      "predictions_3488.json.loss 64\n",
      "nbest_predictions_3488.json 64\n",
      "predictions_3488.json 64\n",
      "bart-base.fts-1.0.train.log 60\n",
      "bart-base.fts-0.25.train.log 60\n",
      "bart-base.fts-0.125.train.log 60\n",
      "bart-base.fts-0.03125.train.log 60\n",
      "bart-base.fts-0.5.train.log 60\n",
      "predictions_dev2-8416.json.loss 53\n",
      "predictions_dev2-8416.json 53\n",
      "nbest_predictions_dev2-8416.json 53\n",
      "predictions_dev2-1376.json.loss 51\n",
      "nbest_predictions_dev2-1376.json 51\n",
      "predictions_dev2-1376.json 51\n",
      "bart-base.fts-0.000244140625.train.log 44\n",
      "predictions_dev2-135616.json 40\n",
      "predictions_dev2-135616.json.loss 40\n",
      "nbest_predictions_dev2-135616.json 40\n",
      "predictions_dev2-271264.json 34\n",
      "nbest_predictions_dev2-271264.json 34\n",
      "predictions_dev2-271264.json.loss 34\n",
      "nbest_predictions_7008.json 30\n",
      "predictions_7008.json 30\n",
      "predictions_7008.json.loss 30\n",
      "nbest_predictions_361696.json 26\n",
      "predictions_361696.json 26\n",
      "predictions_361696.json.loss 26\n",
      "predictions_dev2-16864.json 24\n",
      "nbest_predictions_dev2-16864.json 24\n",
      "predictions_dev2-16864.json.loss 24\n",
      "predictions_dev2-45184.json 24\n",
      "predictions_dev2-45184.json.loss 24\n",
      "nbest_predictions_dev2-45184.json 24\n",
      "nbest_predictions_22496.json 22\n",
      "predictions_22496.json.loss 22\n",
      "predictions_22496.json 22\n",
      "checkpointepoch=1.ckpt 20\n",
      "bart-base.fts-0.0001220703125.train.log 20\n",
      "predictions_dev2-33856.json 16\n",
      "nbest_predictions_dev2-33856.json 16\n",
      "predictions_dev2-33856.json.loss 16\n",
      "predictions_dev2-3488.json 15\n",
      "predictions_dev2-3488.json.loss 15\n",
      "nbest_predictions_dev2-3488.json 15\n",
      "checkpointepoch=2.ckpt 14\n",
      "predictions_dev2-11264.json 13\n",
      "nbest_predictions_dev2-11264.json 13\n",
      "predictions_dev2-11264.json.loss 13\n",
      "nbest_predictions_90336.json 12\n",
      "nbest_predictions_dev2-67744.json 12\n",
      "predictions_90336.json.loss 12\n",
      "predictions_dev2-67744.json.loss 12\n",
      "predictions_dev2-67744.json 12\n",
      "predictions_90336.json 12\n"
     ]
    }
   ],
   "source": [
    "for file in sorted(file2count, key=file2count.get, reverse=True):\n",
    "    if file2count[file] <= 10:\n",
    "        break\n",
    "    print(file, file2count[file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Unnecessary files (don't delete the hotpotQA model ones)\n",
    "# hparams.yaml 36763\n",
    "# merges.txt 7559\n",
    "# config.json 7558\n",
    "# vocab.json 7558\n",
    "# tokenizer_config.json 7558\n",
    "# special_tokens_map.json 7558\n",
    "# training_args.bin 7555\n",
    "# scheduler.pt 5395\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'{os.getenv(\"HOME\")}/checkpoint/complexity'\n",
    "filepath2size = {os.path.join(folder, file): os.stat(os.path.join(folder, file)).st_size for folder, subfolders, files in tqdm(os.walk(path)) for file in files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_file_size_threshold = 1e8\n",
    "num_large_files = 0\n",
    "total_large_file_size = 0\n",
    "for filepath in sorted(filepath2size, key=filepath2size.get, reverse=True):\n",
    "    size = filepath2size[filepath]\n",
    "    total_large_file_size += size\n",
    "    num_large_files += 1\n",
    "    print(filesize.size(size), filepath)\n",
    "    if size < large_file_size_threshold:\n",
    "        break\n",
    "print('# Large Files:', num_large_files)\n",
    "print('Total Large File Size:', filesize.size(total_large_file_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
