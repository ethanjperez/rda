{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"rda.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMIUkqWjkL2m6+V4QLovQC5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gqBAwIKVk359"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ethanjperez/rda/blob/master/rda.ipynb)\n","\n","# **Tutorial**: How to run Rissanen Data Analysis on your own dataset\n","\n","This short notebook shows how you can run Rissanen Data Analysis (RDA) on any dataset, using any model of your choice. To perform RDA, you'll need to compute the Minimum Description Length (MDL) of the labels of your dataset given the inputs. Then, you can modify the dataset inputs (i.e., adding or removing certain features, like nouns) and see how the MDL changes. In this notebook, we'll illustrate how to compute MDL of a dataset in the GLUE benchmark, MRPC, by training BERT models, using the HuggingFace Transformers library.\n","\n","Throughout this tutotial, we'll show you where you need to change the code in order to evaluate the MDL of a different dataset and/or using a different model. You'll only need to change a few lines of code, so it will be quite straightforward. Let's get started!"]},{"cell_type":"markdown","metadata":{"id":"geqhGqDbTDMT"},"source":["## Import Dependencies\n","First, let's import a few basic packages:"]},{"cell_type":"code","metadata":{"id":"Qvx2Wid9jNzv"},"source":["import json\n","import math\n","import os\n","import random\n","import sys"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MidYQqPDx1NO"},"source":["If you're not using Colab, you'll also want to install Pytorch just for this demo, e.g., by following the instructions [here](https://pytorch.org/) or uncommenting and running the below:"]},{"cell_type":"code","metadata":{"id":"Z-F7x4hYx0Y0"},"source":["#!pip install torch"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"--O_cEy0gZfR"},"source":["Next, we'll load some library to train models (with PyTorch, Tensorflow, Jax, or anything else). We'll call some model training function from the library (treating it like a black box), in order to train and test on different subsets of the original dataset (which we'll write to file first). We just need the model training function to return us the loss on unseen test examples. The loss value should be the mean squared error for regression tasks and negative log-likelihood otherwise -- we'll use these values to compute the label description lengths.\n","\n","Here, we train BERT models using HuggingFace Transformers. We've cloned the original repo and modified 5 lines of code (changes [here](https://github.com/ethanjperez/transformers_rda/compare/f52a15897b46ffa40af5c96d3726f0e18e91879b...master)) to have the model training function:\n","1. return test loss after training\n","2. be accessible via an import statement\n","\n","Load this model training function like so:"]},{"cell_type":"code","metadata":{"id":"oop88Gfces3j"},"source":["!pip install datasets\n","!pip install git+https://github.com/ethanjperez/transformers_rda.git\n","import transformers.run_glue as train_model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7mW2or9oh6lF"},"source":["## Specify RDA Experimental Setup\n","Next, let's set a few basic variables (with assertion checks) to set how we'll compute RDA:"]},{"cell_type":"code","metadata":{"id":"tkuKkqAdm-WQ"},"source":["# The number of blocks N we use when sending labels\n","# We train N-1 models, since the first block is sent with a uniform prior\n","num_blocks = 9\n","assert num_blocks >= 1, 'num_blocks must be >= 1'\n","\n","# The minimum/maximum number of examples to train models with\n","min_num_train_samples = 64\n","max_num_train_samples = float('inf') # use all examples\n","assert min_num_train_samples >= 1, 'min_num_train_samples must be >= 1'\n","assert max_num_train_samples >= min_num_train_samples, 'max_num_train_samples must be >= --min_num_train_samples'\n","\n","# The fraction of examples to split off for validation (the rest are used for training)\n","val_frac = 0.1\n","assert 0 <= val_frac < 1, 'val_frac must be >= 0 and < 1'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YvS6XICiCzR-"},"source":["Now, let's set a few task-specific variables. We need to know the range of possible output values, in order to compute the codelength for sending the first block of labels. For MRPC, there are just two possible labels:"]},{"cell_type":"code","metadata":{"id":"rr8SbsO0es50"},"source":["label_range = 2\n","assert label_range > 0, 'label_range must be > 0'\n","\n","uniform_prior_nll = -math.log(1. / float(label_range))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WEGF82G0CypI"},"source":["For text generation or span prediction, `label_range` will be quite large, as there are many possible outputs. For regression, you'll want to set `label_range` to the size of the interval over which outputs can range, e.g., 3.5 if the range is [1., 4.5]. Speaking of regression, let's set a variable to keep track of whether or not we expect to receive mean squared error values from our model training function (so we'll know to convert MSE values to negative log-likelihoods)."]},{"cell_type":"code","metadata":{"id":"mcxI6vofEZif"},"source":["mse = False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"12sgFiUmEX4R"},"source":["Lastly, set the command line arguments you want to use to train your model. We'll need to point the model to the training/validation/test data for each block, but that will change for each block. For now, we can just set those paths to special string `TRAIN_FILE`, `VALIDATION_FILE`, and `TEST_FILE` (we'll replace these with actual file paths later). Here's what this looks like for training a HuggingFace BERT model:"]},{"cell_type":"code","metadata":{"id":"FJqj_arWE8_P"},"source":["training_args = \"--model_name_or_path bert-base-cased --do_train --do_eval --max_seq_length 128 \" + \\\n","    \"--per_device_train_batch_size 32 --learning_rate 2e-5 --num_train_epochs 3 --output_dir checkpoint \" + \\\n","    \"--train_file TRAIN_FILE --validation_file VALIDATION_FILE --test_file TEST_FILE --overwrite_output_dir\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eCCu94DQTbaG"},"source":["Note that `--overwrite_output_dir` will clear the saved results of any previous model training run that saves to the same `--output_dir` (here, `checkpoint/`). This is the behavior that we want, since when we send a new block, we don't want to reload the model, results, etc. for sending an earlier block of data. If you call a different model training function, you'll similarly want to ensure that you aren't accidentally loading the results of previous training runs when you make a new call to the model training function.\n","\n","## Dataset Setup\n","\n","Now that we've specified our RDA setup, let's load our dataset into a list of examples (these can have any data type/structure). We load the MRPC data (just the training set for MDL evaluation) like so:"]},{"cell_type":"code","metadata":{"id":"qZ2s10kYRiWn"},"source":["from datasets import load_dataset\n","dataset = list(load_dataset(\"glue\", \"mrpc\", split='train'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dvPVTsmPIF4f"},"source":["At this point, you can augment or ablate the input data loaded above if desired. We'll just show how to compute MDL on the original MRPC dataset, so we don't do any input modification here.\n","\n","Next, let's randomly order the dataset examples using a fixed random seed:"]},{"cell_type":"code","metadata":{"id":"8zF9U9ICIE5N"},"source":["seed = 0\n","rng = random.Random(seed)\n","rng.shuffle(dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EGkTKz32IhSK"},"source":["To train the model on different subsets of the data, we'll need a function that saves a list of examples to file, in a format that the model training function can read from. Later, we can point the model training function to different training/validation/test data files as needed, for different blocks. Below, we save instances in a way that is compatible with loading data via HuggingFace datasets:"]},{"cell_type":"code","metadata":{"id":"-d0VK0yEU84C"},"source":["def save_data(examples, save_file):\n","    with open(save_file, 'w') as f:\n","        f.writelines('\\n'.join([json.dumps(ex) for ex in examples]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f57Q7kEgJwxH"},"source":["Let's also set the file extension that we want to use to save data files:"]},{"cell_type":"code","metadata":{"id":"YFYJGJIUJ2mi"},"source":["data_file_ext = 'json'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2Bpze-t2KjcC"},"source":["Now, let's compute the starting indices of each block, $t_0, \\dots, t_N$:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"17bySGgXTFvP","executionInfo":{"status":"ok","timestamp":1615053445178,"user_tz":480,"elapsed":32002,"user":{"displayName":"Ethan Perez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhYMrezZ_njsu6ZjIB7bBFynDGFzaIgS3G42znnRVg=s64","userId":"03569540079462035451"}},"outputId":"6cf9f5a9-7c7b-43aa-a51e-825ccef30b00"},"source":["block_size_logscale_increment = (math.log(min(len(dataset), max_num_train_samples)) - math.log(min_num_train_samples)) / (num_blocks - 1)\n","block_start_idxs = [0] + [int(round(math.exp(math.log(min_num_train_samples) + (block * block_size_logscale_increment)))) for block in range(num_blocks)]\n","print('t_0, ..., t_N:', block_start_idxs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["t_0, ..., t_N: [0, 64, 106, 176, 292, 485, 804, 1333, 2211, 3668]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2ryAZ1G_L1hV"},"source":["## Computing Negative Log-Likelihoods\n","\n","Now, we're ready to compute the average negative log-likelihoods (NLLs) for each block.\n","Let's collect the average NLL for each block in a list, adding the NLL for the first block that we computed earlier:"]},{"cell_type":"code","metadata":{"id":"f0w0QYh6MlSa"},"source":["nlls = [uniform_prior_nll]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_LTWT2OCMvjD"},"source":["Now, we create train/val/test splits for sending each data block after the first, and then send each block one by one by calling `train_model.main()` to train a model on a chunk of the data and get the test loss on a new block."]},{"cell_type":"code","metadata":{"id":"KjohoWz4UO4i"},"source":["# Send each block after the first, one by one\n","for send_block in range(1, num_blocks):\n","    # Create the train/validation/test data for sending each block\n","    train_val_dataset = dataset[:block_start_idxs[send_block]] # train/val examples from blocks before the current one\n","    rng.shuffle(train_val_dataset) # shuffle examples for random train vs. val split\n","    val_size = int(round(val_frac * len(train_val_dataset))) # compute size of validation set\n","    block_datasets = { # get list of examples for each split\n","        'train': train_val_dataset[val_size:],\n","        'validation': train_val_dataset[:val_size],\n","        'test': dataset[block_start_idxs[send_block]: block_start_idxs[send_block + 1]],\n","    }\n","\n","    # Save train/validation/test data and add data paths to model training arguments\n","    block_data_dir = 'data/send_block_' + str(send_block) # where we'll save the train/val/test data for sending the current block\n","    os.makedirs(block_data_dir, exist_ok=True)\n","    block_training_args = training_args\n","    for split, block_dataset in block_datasets.items():\n","        block_split_filepath = os.path.join(block_data_dir, split + '.' + data_file_ext)\n","        print('Saving data to:', block_split_filepath)\n","        # Save the data for a single split of data (train, val, or test)\n","        save_data(block_dataset, block_split_filepath)\n","        assert (split.upper() + '_FILE') in training_args, 'Expected ' + split.upper() + '_FILE in training_args'\n","        # Point training arguments to this block's train/val/test data\n","        block_training_args = block_training_args.replace(split.upper() + '_FILE', block_split_filepath)\n","\n","    # Set command line args for model training\n","    sys.argv = [train_model.__file__] + block_training_args.split()\n","    # Call main function to train model with above args, to get test NLL on this block\n","    block_nll = train_model.main()\n","    nlls.append(block_nll)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wnChtchrLHII"},"source":["We're basically done now that we've gotten the losses on each block. If the model training function (`train_model.main()`) returned a mean squared error loss values instead of NLL (e.g., for regression), we'll need to convert the loss values to NLLs:"]},{"cell_type":"code","metadata":{"id":"_qld3-hrYt95"},"source":["def mse2nll(nll, std_dev=1.):\n","    \"\"\"\n","    Utility to convert expected mean squared error (MSE) to expected NLL.\n","    Here, MSE = (y' - y)^2, where y' is the predicted label and y is the true label.\n","    We treat all regression/MSE predictions as a mean with a fixed std_dev.\n","    We use std_dev=1 as a default, but other values may work better, e.g., if chosen on dev.\n","    \"\"\"\n","    return (nll / (2. * (std_dev ** 2))) + math.log(std_dev * math.sqrt(2 * math.pi))\n","\n","if mse:\n","    nlls = [mse2nll(mse) for mse in nlls]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FGZ2_MZ5K-hD"},"source":["Finally, we'll compute the per-sample codelengths (in bits) for different blocks (in order from earliest to latest):"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nBb-haI3UcfR","executionInfo":{"status":"ok","timestamp":1615053860225,"user_tz":480,"elapsed":447034,"user":{"displayName":"Ethan Perez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhYMrezZ_njsu6ZjIB7bBFynDGFzaIgS3G42znnRVg=s64","userId":"03569540079462035451"}},"outputId":"59330e22-e280-4388-adbd-3b392e3ffafd"},"source":["codelengths = [nll / math.log(2) for nll in nlls]\n","print('Codelengths:', codelengths)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Codelengths: [1.0, 0.8554979437184423, 0.7470464580062841, 0.93560875236022, 0.8891608818937488, 0.8422681783008208, 0.8201923132534198, 0.7674828124430099, 0.7314436759720575]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UwIIPa5RoXsn"},"source":["To get MDL, let's compute the number of examples that were in each block:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xl5DB8myLRvn","executionInfo":{"status":"ok","timestamp":1615053860226,"user_tz":480,"elapsed":447030,"user":{"displayName":"Ethan Perez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhYMrezZ_njsu6ZjIB7bBFynDGFzaIgS3G42znnRVg=s64","userId":"03569540079462035451"}},"outputId":"15a1265b-1cea-4fa1-a417-92ba3d19cc45"},"source":["block_sizes = [(block_start - block_end) for block_start, block_end in zip(block_start_idxs[1:], block_start_idxs[:-1])]\n","print('Block Sizes:', block_sizes)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Block Sizes: [64, 42, 70, 116, 193, 319, 529, 878, 1457]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8gST-snjLUBP"},"source":["Then, we can compute the codelength for sending each block and sum those values to get MDL:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k9H7_DcULSPl","executionInfo":{"status":"ok","timestamp":1615053860227,"user_tz":480,"elapsed":447026,"user":{"displayName":"Ethan Perez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhYMrezZ_njsu6ZjIB7bBFynDGFzaIgS3G42znnRVg=s64","userId":"03569540079462035451"}},"outputId":"6158e4cd-b0c1-41c1-d448-62a5559a1b4d"},"source":["mdl = sum(block_size * per_sample_codelength for block_size, per_sample_codelength in zip(block_sizes, codelengths))\n","print('MDL:', round(mdl), 'bits')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["MDL: 2874 bits\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xgipGy7XLjDj"},"source":["\n","And that's how you compute MDL! To conduct RDA, just modify the dataset inputs (where described above) and see how the MDL changes. Now you're ready to analyze your own datasets 🥳"]}]}